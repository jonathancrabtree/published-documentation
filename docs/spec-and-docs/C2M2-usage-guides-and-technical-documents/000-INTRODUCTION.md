# The Common Fund Data Ecosystem's Crosscut Metadata Model (CFDE C2M2)

This document introduces the Crosscut Metadata Model
([C2M2](../../CFDE-glossary.md#c2m2)), a
flexible metadata standard for describing experimental resources in
biomedicine and related fields. The Common Fund Data Ecosystem
group is creating a new computing infrastructure, with C2M2 as its
organizing principle, to offer the health research community an
unprecedented array of intersectional data tools. The C2M2 system will
connect researchers with scale-powered statistical analysis
methods; deep, seamless searching across experimental data generated by
different projects and organizations; and new ways to aggregate
and integrate experimental data from different sources to
facilitate scientific replication and to drive new discoveries.

Using this new infrastructure, Common Fund data coordinating centers
([DCCs](../../CFDE-glossary.md#dcc)) will
share structured, detailed information ([metadata](../../CFDE-glossary.md#metadata))
about their experimental resources with the research
community at large, widening and deepening access to usable
observational data. One immediate consequence will be a
drastic simplification in the effort required to perform
meta-analysis of results from multiple independent teams
studying similar health-related phenomena.

## DCC Metadata Submissions

DCCs collect and provide metadata submissions
(C2M2 [instances](../../CFDE-glossary.md#c2m2-instance))
to CFDE describing experimental resources within their purview. Each
submission is a set of tab-separated value files
([TSVs](../../CFDE-glossary.md#tsv));
precise formatting requirements for these filesets are specified by
[JSON Schema documents](../C2M2-JSON-Schemas/),
each of which is an instance of the
[Data Package](http://frictionlessdata.io/docs/data-package/)
meta-specification published by the
[Frictionless Data](http://frictionlessdata.io/)
group. The Data Package meta-specification is a toolkit for
defining format and content requirements for files so that
automatic validation can be performed on those files, just
as a database management system stores definitions for
database tables and automatically validates incoming data
based on those definitions. Using this toolkit, the C2M2 JSON
Schema specifications lay out
[foreign-key](../../CFDE-glossary.md#foreign-key)
relationships between metadata fields (TSV columns), rules
governing missing data, required content types for particular fields,
and other similar database management constraints to define
basic structural integrity for C2M2 metadata submissions.
During the
[C2M2 ingestion process](../../CFDE-glossary.md#c2m2-ingestion-process),
the C2M2 software infrastructure uses these specifications
to automatically validate format compliance and submission integrity,
prior to loading metadata into its central database. Once loaded,
metadata are used to fuel downstream services like search results,
customized statistical summaries, dynamic display graphics, and asset
browsing within experimental resource collections.

## C2M2 Levels

CFDE offers DCCs three alternative metadata submission
formats (C2M2 Levels 0, 1 and 2), each of which is automatically
interoperable with the entire C2M2 software ecosystem. Levels
are tiered primarily according to increasing complexity.
The general idea is that DCC resource collections can be
represented quickly (and thus begin driving downstream
applications quickly) using metadata encoded at lower (simpler)
C2M2 levels: over time, and as feasible, DCC data managers
can upgrade their C2M2 metadata submissions by expanding
into higher levels.

C2M2 Levels 0, 1 and 2 are increasingly large and complex variants of the
same metadata model (C2M2): each level is a defined collection of
data tables (encoded as TSVs: see above on
[submissions](#dcc-metadata-submissions)). Level 0 defines just
one short `file` table; Level 1 provides a larger `file` table than
Level 0 (more fields), adds more tables describing other
basic biomedical resource concepts including `biosample`,
`subject`, and `project`, and introduces ways to express simple
relationships between records in different tables; Level 2 is
an ever-growing mature metadata interchange standard, customized
to advanced DCC metadata needs: it contains all Level 1 information,
plus a library of more detailed metadata objects and extensions to
existing objects. Lower levels are strict subsets of higher ones:
Level 1's `file` table contains all Level 0 `file` fields and
more; Level 2's `biosample` is an expanded superset of the Level
1 `biosample`, etc. Upgrades from one level to the next are
therefore limited by design to be done only by expansion: moving
up a level will not require DCCs to make changes to any metadata
already provided.

A foundational purpose of the C2M2 system is to facilitate
metadata harmonization: finding ways wherever possible to
represent comparable things in standard ways, without compromising
meaning, context or accuracy. In addition to complexity
management, C2M2 levels are also intended to roughly encapsulate
groups of concepts according to increasing harmonization
difficulty.

Some examples, sorted by increasingly heavy challenges to harmonization:

* All DCCs have file resources, describable (at a _very_ high level)
in a standard, noncontroversial way (size + filename: [Level 0](./001-C2M2-LEVEL-0.md)).
* In addition to data files, virtually all DCCs deal in some way
with biosamples and/or subjects: metadata describing basic aspects
of these common concepts can be fairly (if still quite broadly) expressed by a
shared model ([Level 1](./002-C2M2-LEVEL-1.md)), thereby enabling the beginnings of cross-dataset search
and analysis.
* Many DCCs have at least some specialized data, unique to their
own spheres of operation, which (at least for some time) will not be
meaningful candidates for system-level harmonization ([Level 2](./003-C2M2-LEVEL-2.md) includes specialized
extension modeling).

Most DCCs already have some form of internal metadata model in use
for their own curation operations. C2M2 integration of similar but
distinct packages of important information, taken from multiple
independently-developed custom DCC metadata systems (including e.g.
metadata describing people and organizations, data provenance relationships,
experimental protocols, protected data, or detailed event
sequences), will require ongoing, iterative, case-based design
and consensus-driven decision-making, often coordinated across multiple
independent research groups. Design and decision-making in such
contexts will require long-term planning, testing
and execution. Metadata difficult (or even impossible) to
integrate and harmonize is thus handled as part of the ongoing
evolution and expansion of Level 2, leaving Level 1 tasked with
supporting relatively universal, simple and uncontroversial
metadata concepts to maintain streamlined development and deployment of
important core metadata packages without unnecessarily blocking feasible
tasks to wait on more expensive custom integration.

With the design of C2M2, we are splitting the difference
between the ease of evolution inherent in a simple model and
the operational power provided to downstream applications by more
complicated and difficult-to-maintain extended frameworks.

Modeling and data wrangling are always difficult, even for
experts. Part of the goal of the level system
is to compartmentalize the C2M2 model so as to maintain flexibility --
especially during developmental phases -- in order to best
accommodate mutual learning between DCCs and CFDE as the
construction of this federated metadata system progresses. It
is generally far more expensive and error-prone to repeatedly
change a complex, over-built, inseparable, monolithic model than it is
to build one gradually from a simpler core of agreement which
can be relatively quickly stabilized while more specialized
branches are built in parallel and transitioned into more general use.

At any given moment, participating Common Fund DCCs will
span a broad range of experience and available funding,
based on mission details and lifecycle phases. DCCs with
advanced, operationalized metadata modeling systems of
their own should not encounter arbitrary barriers to
C2M2 support for more extensive relational modeling of
their metadata if they want it; CFDE will maintain such
support by iteratively refining Level 2
according to needs identified while working with DCCs
already wielding complex metadata models. Newer or smaller
DCCs, by contrast, may not have enough readily-available
information to feasibly describe their experimental resources
using Level 2 structures (either existing or proposed): C2M2
Level 1 thus also aims to actively support such cases by
offering simpler but still well-structured metadata models
where metadata has already harmonized across other DCCs, lowering
barriers to rapid entry into the data ecosystem and meaningful
participation in downstream services.

A C2M2 topic requiring special attention is the use of _identifiers_.

--------------------------------------------------------------------------------

### C2M2 identifiers

* _Two complementary identifier slots for DCC-issued records_
    * `persistent_id`: _persistent and resolvable ID (ideal, but optional)_
    * `id_namespace`, `local_id`: _2-part key is as least-common denominator_
* _The optional persistent identifier is a DOI, ARK, MINID, etc._
* _The 2-element composite identifier conveys fragments of a record URI_
    * `local_id` _bears a name from some namespace, e.g. an accession ID_
    * `id_namespace` _specifies which namespace, i.e. left-hand side of a URI_
    * _concatenation of namespace + local yields the full record URI_
    * _URIs are cheap and easy: low barrier to entry, no hosting requirements_
* _To steer users directly to data, we require_ `persistent_id`_!_
* _Otherwise, we can steer users towards the DCC contact._
* _For consistency, we repeat this scheme on several entity tables._

_Not all DCCs arrive having adopted robust, persistent and resolvable identifiers,
or we could just mandate their use to identify all records. We need to
support different DCC identifier maturity levels, and so we need to keep_
`persistent_id` _optional._

_We add a 2-part composite identifier as something which can lower the barrier
to entry: this is a URI that has been split into two parts. The web rules for
forming URIs are very flexible: it takes essentially no cost and no real
infrastructure to generate URIs, which are just rules for namespace hygiene
laying out how a DCC can claim a namespace out of the ether, ideally rooted in
some other basic name they own such as a DNS name (website domain) or even
just an email address._

_(For those who don’t know, the difference between a URI and a URL is that a
URI is just an identifier.  It doesn’t have to address any actual web server
which responds to messages, so you can produce URIs all day long and never
worry about hosting costs, availability, etc.)_

_The core idea is that most DCCs will have some accession ID or other
locally-unique key for their assets already. They can copy that value
into the_ `local_id` _part or define some other mapping of their own
choosing, there. Then, they can either define a new_ `id_namespace` _or pass
through an applicable, existing URI prefix as the_ `id_namespace` _component.
As long as each DCC follows the web rules to use an_ `id_namespace` _they “own”,
collisions are automatically avoided (where two DCCs might try to use the
same composite identifier)._

_We also allow for the use of persistent, resolvable identifiers for things
which are not really data. We suspect that many of the same practical
benefits of these identifiers for data might apply to other entity
types, even if resolution might lead to landing pages and contact
info which at most guides users to documentation or other possible
actions they might take in the real world or in the parallel
bureaucratic world. (Attempting to directly download subjects or
biosamples might trigger some unexpected and unpleasant -- although
possibly comical -- downstream side effects.)_

--------------------------------------------------------------------------------

* _For a DCC already issuing persistent, resolvable IDs_
    * `persistent_id`: _fill with canonical ID_
    * `id_namespace`, `local_id`: _fill with (split) copy of canonical ID_
* _For a DCC already issuing relatively stable URIs_
    * `persistent_id`: _leave blank until ready_
    * `id_namespace`, `local_id`: _fill with (split) copy of URI_
* _For a DCC already issuing local accession IDs_
    * `persistent_id`: _leave blank until ready_
    * `local_id`: _fill with local accession ID_
    * `id_namespace`: _choose an appropriate namespace URI-prefix_
* _For a DCC without local ID stability_
    * _Need to invent something approximating accession ID and proceed as above_

_If a DCC already uses persistent identifiers such as DOIs, ARKs, or_
_other short identifiers resolvable by some name-to-thing service then they can_
_just put that value into all the identifier fields:_

* _verbatim in the_ `persistent_id` _field so that consumers know a_ `persistent_id` _is available for this record_
* _split and replicated into the_ `id_namespace` _and_ `local_id` _fields so that the core C2M2 requirement for a record key is met_
* _there is no need for the DCC to issue and juggle two separate identifier formats, but the compromise C2M2 format requires the fields to be populated_

_If a DCC already uses URIs or URLs for entities having a one-to-one
correspondence to C2M2 record concepts, they can split that URI or
URL into a namespace prefix part and a final local part and use
those values to fill the 2-part composite record identifier. They would
probably leave_ `persistent_id` _blank._

_If a DCC only has local identifiers for such entities, they can put
that in the_ `local_id` _part and then fabricate a new_ `id_namespace`
_representing their DCC or the sub-organizational scope where these
local identifiers are indeed unique. The same _ `id_namespace` _should
be reused for all peer records with local parts coming from the
same DCC naming system._

_Having stable identifier management is, unavoidably, basic
“table stakes” for a DCC to produce reusable data. Archiving
and indexing options like those provided by C2M2 are extremely
limited in the absence of some method of persistent
bookkeeping to track inventory: persistent identifiers are
a core requirement precisely because without them, federated
views of resource metadata from multiple DCCs cannot be maintained._

--------------------------------------------------------------------------------
